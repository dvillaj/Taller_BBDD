{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Riak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import riak\n",
    "from pprintpp import pprint as pp\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import uuid\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de información en Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partimos del dataset normalizado y lo desnormalizamos para guardarlo todo junto en RIAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_mov = pd.read_excel(\"../../data/black.xlsx\", sheet_name= \"Movimientos\",  engine='openpyxl')\n",
    "df_miembros = pd.read_excel(\"../../data/black.xlsx\", sheet_name= \"Miembros\",  engine='openpyxl')\n",
    "df = pd.merge(df_mov, df_miembros, on = ['id_miembro'], how = 'inner')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Riak ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# connect to database\n",
    "cliente = riak.RiakClient()\n",
    "cliente.ping()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos un bucket para guardar los movimientos en formato JSON y otro para guardar el importe acumulado por miembro.\n",
    "\n",
    "En el bucket de movimientos utilizamos una clave autogenerada (no vamos a poder localizar los movimientos por clave) y en el bucket con el importe acumulado la clave es el nombre de la persona en formato HASH, para no tener problemas ni con los espacios del nombre ni con los acentos\n",
    "\n",
    "Se van a crear los siguientes buckets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "table {float:left}\n",
    "</style>\n",
    "\n",
    "|bucket|Clave|Contenido|\n",
    "|: -|-|-|\n",
    "|movimientos|Marca temporal|Todos los datos del dataset en formnato JSON y desnormalizados|\n",
    "|acum_importes|Código HASH de la persona que realiza el movimiento|Mapa con el nombre de la persona y el importe acumulado|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El bucket de movientos tendrá los siguientes índices:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Nombre del índice|Contenido|¿Que busquedas permite hacer?|\n",
    "|-|-|-|\n",
    "|idx_miembro_bin|Nombre de la persona|Localizar movimientos de una persona concreta|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "BUCKET_MOVIMIENTOS = 'movimientos'\n",
    "BUCKET_ACUM_IMPORTES = 'acum_importes'\n",
    "\n",
    "bucket_mov = cliente.bucket(BUCKET_MOVIMIENTOS)\n",
    "bucket_acum_importes = cliente.bucket_type('maps').bucket(BUCKET_ACUM_IMPORTES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para eliminar los datos de un BUCKET de Riak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def drop_keys(bucket):\n",
    "    for keys in bucket.stream_keys():\n",
    "        for key in keys:\n",
    "            bucket.delete(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Borramos los datos ..\n",
    "drop_keys(bucket_mov)\n",
    "drop_keys(bucket_acum_importes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserción de información en Riak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para generar los datos en formato JSON partimos del DataFrame de Pandas y lo exportamos a JSON (en formato String) para luego cargarlo en un diccionario de Python\n",
    "\n",
    "Observa que cuando se genera el dato en formato JSON, los campos fechas se almacenan como un [TIMESTAMP de unix](http://www.unixtimestamp.com), por lo que habría que volver a convertirlo a fecha según el caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "json_string = df.to_json(orient = 'records')\n",
    "json_list = json.loads(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(len(json_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pp(json_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a utilizar el nombre de la persona como clave, por lo que necesitamos convertirla previamente a un código que no lleve ni espacios ni acentos.\n",
    "\n",
    "Este es precisamente el objetivo de la siguiente función ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_string(s):\n",
    "    s_utf8 = s.encode('utf-8')\n",
    "    return hashlib.md5(s_utf8).hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recorremos el dataset de movimientos, almacenando la información tanto en el bucket de movimientos como en el bucket que acumula los movimientos por cliente.\n",
    "\n",
    "En este último utilizamos una funcionalidad que nos da Riak para guardar la información tipificada. Utilizamos un mapa que tiene dos elementos: Un registro donde guardamos el nombre del cliente y un contador donde guardamos el importe (sin decimales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Bucle de carga de datos ...\n",
    "for movimiento_json in json_list:\n",
    "    key = uuid.uuid4().hex\n",
    "    hash_nombre =  hash_string(movimiento_json[\"nombre\"])\n",
    "    \n",
    "    movimiento = bucket_mov.new(key, movimiento_json)\n",
    "    movimiento.add_index('idx_miembro_bin', hash_nombre)\n",
    "    movimiento.store()\n",
    "    \n",
    "    map_nombre = bucket_acum_importes.new(hash_nombre)\n",
    "    map_nombre.registers['nombre'].assign(movimiento_json[\"nombre\"])\n",
    "    map_nombre.counters['importe'].increment(int(round(movimiento_json[\"importe\"] * 100)))\n",
    "    map_nombre.store()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in bucket_mov.get_keys()[0:3]:\n",
    "    data = bucket_mov.get(key).data\n",
    "    print('%s -> %s' % (key, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in bucket_acum_importes.get_keys()[0:3]:\n",
    "    data = bucket_acum_importes.get(key)\n",
    "    print('%s -> %s' % (key, data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de información en Riak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente función partimos del objeto JSON que nos devuelve RIAK y generamos un DataFrame Pandas.\n",
    "\n",
    "En el caso de la fecha, lo convertimos desde un UNIX Timestamp al formato correcto para Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_pandas(rows):\n",
    "    # Convertimos el objeto JSON en un objeto pandas \n",
    "    df = pd.read_json(json.dumps(rows))\n",
    "    \n",
    "    if 'fecha' in df.columns:\n",
    "        # Las fechas están en formato UNIX TIMESTAMP. Las volvemos a convertir a formato Date...\n",
    "        df = df.assign(fecha = pd.to_datetime(df.fecha, unit = 'ms'))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura del bucket de movimientos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos todos los movimientos de la base de datos y lo guardamos en un objeto Pandas, ya que hay ciertas preguntas que no pueden resolverse directamente por esta base de datos\n",
    "\n",
    "Recuerda que RIAK permite obtener información de un clave, pero no le es posible devolver la información ordenada ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "for keys in bucket_mov.stream_keys():\n",
    "    for key in keys:\n",
    "        # print('Key %s' % key )\n",
    "        rows.append(bucket_mov.get(key).data)\n",
    "        \n",
    "# Convertimos el objeto json en un objeto pandas \n",
    "df_movimientos = json_to_pandas(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_movimientos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Los 10 movimientos mas caros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta consulta no la podemos contestar directamente con la Base de Datos por lo que nos apoyamos en un proceso en el cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_movimientos \\\n",
    "    .sort_values('importe', ascending=False)\\\n",
    "    .filter(['nombre', 'fecha', 'actividad_completa', 'importe']) \\\n",
    "    .head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura a través de un índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "keys = bucket_mov.stream_index(\"idx_miembro_bin\", hash_string(u\"Ildefonso José Sánchez Barcoj\"))\n",
    "for keys in keys.results:\n",
    "    for movimiento_key in keys:\n",
    "        rows.append(bucket_mov.get(movimiento_key).data)\n",
    "    \n",
    "df = json_to_pandas(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Los movimientos de una persona concreta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener los movimientos de una persona en concreto si podemos utilizar el índice que habíamos creado Ad-hoc, aunque la ordenación se realiza en Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df \\\n",
    "    .sort_values('importe', ascending=False) \\\n",
    "    .filter(['nombre', 'fecha', 'actividad_completa', 'importe']) \\\n",
    "    .head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura de una información agregada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La información agregada está en un mapa, por lo que tenemos que procesarla y convertirla a formato JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "for keys in bucket_acum_importes.stream_keys():\n",
    "    #print(keys)\n",
    "    for key in keys:\n",
    "        map_nombre = bucket_acum_importes.get(key)\n",
    "        rows.append({'nombre' : map_nombre.registers['nombre'].value,\n",
    "                     \"importe\" : float(map_nombre.counters['importe'].value) / 100})\n",
    "        \n",
    "# Convertimos el objeto json en un objeto pandas \n",
    "df = json_to_pandas(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Las 10 personas que mas han gastado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fácil si disponemos de un agregado. Utilizamos Pandas para ordenar la información ..,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.sort_values('importe', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
